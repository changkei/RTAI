{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "legitimate-consultancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_path = 'C:/Users/keith/Desktop/School/RTAI/HW/HW4'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True) # <1>\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True) # <2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enormous-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                                      transform = transforms.Compose([\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                               (0.2470, 0.2435, 0.2616))\n",
    "                                      ]))\n",
    "\n",
    "transformed_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
    "                                      transform = transforms.Compose([\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                               (0.2470, 0.2435, 0.2616))\n",
    "                                      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assumed-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "funded-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "downtown-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 4, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 4, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * 4)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fallen-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1): \n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader: \n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels) \n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "close-reliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-21 19:00:47.749417 Epoch 1, Training loss 2.2499072066963177\n",
      "2021-04-21 19:03:37.739704 Epoch 10, Training loss 1.4114447257402913\n",
      "2021-04-21 19:06:47.138543 Epoch 20, Training loss 1.2064939247220374\n",
      "2021-04-21 19:10:03.887293 Epoch 30, Training loss 1.127949120214833\n",
      "2021-04-21 19:13:22.173948 Epoch 40, Training loss 1.0815116263868865\n",
      "2021-04-21 19:16:39.799366 Epoch 50, Training loss 1.0496227305258632\n",
      "2021-04-21 19:19:57.461067 Epoch 60, Training loss 1.0261218200254318\n",
      "2021-04-21 19:23:15.849968 Epoch 70, Training loss 1.0076505564667684\n",
      "2021-04-21 19:26:33.675887 Epoch 80, Training loss 0.9944835003379666\n",
      "2021-04-21 19:29:51.504205 Epoch 90, Training loss 0.9836963636948325\n",
      "2021-04-21 19:33:09.075289 Epoch 100, Training loss 0.9706952953734971\n",
      "2021-04-21 19:36:26.332383 Epoch 110, Training loss 0.9605045636444141\n",
      "2021-04-21 19:39:46.168899 Epoch 120, Training loss 0.9545677430032159\n",
      "2021-04-21 19:43:03.832999 Epoch 130, Training loss 0.94633189522092\n",
      "2021-04-21 19:46:21.316727 Epoch 140, Training loss 0.9395364928428475\n",
      "2021-04-21 19:49:38.679938 Epoch 150, Training loss 0.9332678317261474\n",
      "2021-04-21 19:52:55.910907 Epoch 160, Training loss 0.929713285182748\n",
      "2021-04-21 19:56:15.439773 Epoch 170, Training loss 0.9230674521240128\n",
      "2021-04-21 19:59:41.629330 Epoch 180, Training loss 0.9183957598093525\n",
      "2021-04-21 20:02:56.352724 Epoch 190, Training loss 0.9148125607339318\n",
      "2021-04-21 20:06:11.458326 Epoch 200, Training loss 0.9109386715590192\n",
      "3942.386960506439 seconds\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64, shuffle=True)\n",
    "model = Net()\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "end = time.time()\n",
    "\n",
    "ttime = end - start\n",
    "print(str(ttime) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "electoral-madison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.68\n",
      "Accuracy val: 0.63\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(transformed_cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attractive-mandate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4310, [432, 16, 1152, 8, 288, 4, 2048, 32, 320, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel()\n",
    "              for p in model.parameters()\n",
    "              if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
