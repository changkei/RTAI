{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "integrated-dating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_path = 'C:/Users/keith/Desktop/School/RTAI/HW/HW4'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True) # <1>\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True) # <2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "close-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                                      transform = transforms.Compose([\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                               (0.2470, 0.2435, 0.2616))\n",
    "                                      ]))\n",
    "\n",
    "transformed_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
    "                                      transform = transforms.Compose([\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                               (0.2470, 0.2435, 0.2616))\n",
    "                                      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alien-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "filled-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {6: 0, 7: 1, 8: 2, 9: 3}\n",
    "class_names = ['frog','horse','ship','truck']\n",
    "cifar4 = [(img, label_map[label])\n",
    "          for img, label in transformed_cifar10 \n",
    "          if label in [6, 9]]\n",
    "cifar4_val = [(img, label_map[label])\n",
    "              for img, label in transformed_cifar10_val\n",
    "              if label in [6, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interim-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nonprofit-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1): \n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader: \n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels) \n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quarterly-australia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-21 17:45:39.486608 Epoch 1, Training loss 0.6763547581092567\n",
      "2021-04-21 17:45:54.381015 Epoch 10, Training loss 0.20515698787702877\n",
      "2021-04-21 17:46:10.127626 Epoch 20, Training loss 0.1202107252802249\n",
      "2021-04-21 17:46:25.955342 Epoch 30, Training loss 0.08290823782752653\n",
      "2021-04-21 17:46:41.752767 Epoch 40, Training loss 0.07055716647226719\n",
      "2021-04-21 17:46:57.455806 Epoch 50, Training loss 0.053512479721384634\n",
      "2021-04-21 17:47:13.268600 Epoch 60, Training loss 0.05071634403355776\n",
      "2021-04-21 17:47:29.034498 Epoch 70, Training loss 0.04375589726297007\n",
      "2021-04-21 17:47:44.714861 Epoch 80, Training loss 0.039451634265173965\n",
      "2021-04-21 17:48:00.503049 Epoch 90, Training loss 0.03331922078475499\n",
      "2021-04-21 17:48:16.246739 Epoch 100, Training loss 0.032592148228643376\n",
      "2021-04-21 17:48:32.002179 Epoch 110, Training loss 0.026768304557379358\n",
      "2021-04-21 17:48:48.251126 Epoch 120, Training loss 0.04254991645964788\n",
      "2021-04-21 17:49:04.050123 Epoch 130, Training loss 0.021803904528682163\n",
      "2021-04-21 17:49:19.847107 Epoch 140, Training loss 0.019327055939449483\n",
      "2021-04-21 17:49:35.525306 Epoch 150, Training loss 0.017927896215099912\n",
      "2021-04-21 17:49:51.504870 Epoch 160, Training loss 0.01819891458307541\n",
      "2021-04-21 17:50:07.377066 Epoch 170, Training loss 0.0135591449012096\n",
      "2021-04-21 17:50:23.200682 Epoch 180, Training loss 0.012084546531580247\n",
      "2021-04-21 17:50:41.206185 Epoch 190, Training loss 0.011362558155866329\n",
      "2021-04-21 17:50:57.862035 Epoch 200, Training loss 0.008791648065482242\n",
      "319.99604868888855 seconds\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar4, batch_size=64, shuffle=True)\n",
    "model = Net()\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "end = time.time()\n",
    "\n",
    "ttime = end - start\n",
    "print(str(ttime) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unsigned-statement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.98\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar4_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unable-flavor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18156, [432, 16, 1152, 8, 16384, 32, 128, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel()\n",
    "              for p in model.parameters()\n",
    "              if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
