{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accessible-joint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_path = 'C:/Users/keith/Desktop/School/RTAI/HW/HW4'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True) # <1>\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True) # <2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "standing-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                                      transform = transforms.Compose([\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                               (0.2470, 0.2435, 0.2616))\n",
    "                                      ]))\n",
    "\n",
    "transformed_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
    "                                      transform = transforms.Compose([\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                               (0.2470, 0.2435, 0.2616))\n",
    "                                      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desperate-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "binding-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bulgarian-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "analyzed-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1): \n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader: \n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels) \n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "seasonal-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-21 17:51:37.096098 Epoch 1, Training loss 2.015313145602146\n",
      "2021-04-21 17:54:24.752637 Epoch 10, Training loss 1.182037341777626\n",
      "2021-04-21 17:57:31.533816 Epoch 20, Training loss 0.9984736375491637\n",
      "2021-04-21 18:00:38.223945 Epoch 30, Training loss 0.9112453408101026\n",
      "2021-04-21 18:03:42.971171 Epoch 40, Training loss 0.8569323506272967\n",
      "2021-04-21 18:06:55.143347 Epoch 50, Training loss 0.8124551888164657\n",
      "2021-04-21 18:10:11.599280 Epoch 60, Training loss 0.7789125465752219\n",
      "2021-04-21 18:14:10.376259 Epoch 70, Training loss 0.7510147317672324\n",
      "2021-04-21 18:18:16.963214 Epoch 80, Training loss 0.7276073113807937\n",
      "2021-04-21 18:22:12.751148 Epoch 90, Training loss 0.706681099960871\n",
      "2021-04-21 18:26:16.754904 Epoch 100, Training loss 0.6887522609642399\n",
      "2021-04-21 18:30:19.706138 Epoch 110, Training loss 0.672220994596896\n",
      "2021-04-21 18:33:33.177110 Epoch 120, Training loss 0.6583433915739474\n",
      "2021-04-21 18:36:41.705750 Epoch 130, Training loss 0.6451079074455344\n",
      "2021-04-21 18:39:54.550546 Epoch 140, Training loss 0.6317303636494804\n",
      "2021-04-21 18:43:05.349415 Epoch 150, Training loss 0.6230520796592888\n",
      "2021-04-21 18:46:16.834190 Epoch 160, Training loss 0.6124079518991968\n",
      "2021-04-21 18:49:29.035356 Epoch 170, Training loss 0.6008278701997474\n",
      "2021-04-21 18:52:42.189631 Epoch 180, Training loss 0.5921638632369468\n",
      "2021-04-21 18:55:55.848971 Epoch 190, Training loss 0.5843044155660797\n",
      "2021-04-21 18:59:08.329610 Epoch 200, Training loss 0.5768447382104062\n",
      "4069.9344680309296 seconds\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64, shuffle=True)\n",
    "model = Net()\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "end = time.time()\n",
    "\n",
    "ttime = end - start\n",
    "print(str(ttime) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nutritional-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.78\n",
      "Accuracy val: 0.63\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(transformed_cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cardiac-sauce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18354, [432, 16, 1152, 8, 16384, 32, 320, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel()\n",
    "              for p in model.parameters()\n",
    "              if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
